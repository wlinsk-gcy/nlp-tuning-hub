{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 安装依赖\n",
    "\n",
    "如果当前环境已经有相关依赖了，则不用执行"
   ],
   "id": "365115280dd296ea"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "!pip install transformers[torch] datasets==3.6.0 evaluate",
   "id": "7be286f88eda7773"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 加载数据",
   "id": "8723249e465de590"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "model_checkpoint = \"bert-base-uncased\"\n",
    "batch_size = 16\n",
    "\n",
    "datasets = load_dataset(\"swag\",\"regular\")\n"
   ],
   "id": "c8e4d1b5975850bb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 你可以查看dataset对象都封装了什么东西\n",
    "datasets"
   ],
   "id": "8e4082b5ba3d47e5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 数据集可视化\n",
    "\n",
    "为了能够进一步理解数据长什么样子，下面的函数将从数据集里随机选择几个例子进行展示。"
   ],
   "id": "acfb42068227444e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from datasets import ClassLabel, Sequence\n",
    "import random\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "def show_random_elements(dataset, num_examples=10):\n",
    "  assert num_examples <= len(dataset), \"Can't pick more elements than there are in the dataset.\"\n",
    "  picks = []\n",
    "  for _ in range(num_examples):\n",
    "      pick = random.randint(0, len(dataset)-1)\n",
    "      while pick in picks:\n",
    "          pick = random.randint(0, len(dataset)-1)\n",
    "      picks.append(pick)\n",
    "\n",
    "\n",
    "  df = pd.DataFrame(dataset[picks])\n",
    "  for column, typ in dataset.features.items():\n",
    "    if isinstance(typ, ClassLabel):\n",
    "        df[column] = df[column].transform(lambda i: typ.names[i])\n",
    "    elif isinstance(typ, Sequence) and isinstance(typ.feature, ClassLabel):\n",
    "        df[column] = df[column].transform(lambda x: [typ.feature.names[i] for i in x])\n",
    "  display(HTML(df.to_html()))\n",
    "\n",
    "show_random_elements(datasets[\"train\"], num_examples=2)"
   ],
   "id": "4db19a0d02b8380f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "以下是一个完整的数据样本示例：",
   "id": "ec932b279f50b5bf"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def show_one(example):\n",
    "    print(f\"Context: {example['sent1']}\")\n",
    "    print(f\"  A - {example['sent2']} {example['ending0']}\")\n",
    "    print(f\"  B - {example['sent2']} {example['ending1']}\")\n",
    "    print(f\"  C - {example['sent2']} {example['ending2']}\")\n",
    "    print(f\"  D - {example['sent2']} {example['ending3']}\")\n",
    "    print(f\"\\nGround truth: option {['A', 'B', 'C', 'D'][example['label']]}\")\n",
    "\n",
    "show_one(datasets[\"train\"][0])"
   ],
   "id": "e362dc113a262778"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 数据预处理",
   "id": "a39f7eb0c47c4d20"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, use_fast=True)\n",
    "ending_names = [\"ending0\", \"ending1\", \"ending2\", \"ending3\"]\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    # 将题目重复4次，用来匹配每一个选项\n",
    "    first_sentences = [[context] * 4 for context in examples[\"sent1\"]]\n",
    "    # 获取选项头\n",
    "    question_headers = examples[\"sent2\"]\n",
    "    # 把每个选项头对应的4个结尾，拼接到选项头上\n",
    "    second_sentences = [[f\"{header} {examples[end][i]}\" for end in ending_names] for i, header in enumerate(question_headers)]\n",
    "\n",
    "    # 将二维的展开成一维结构\n",
    "    first_sentences = sum(first_sentences, [])\n",
    "    second_sentences = sum(second_sentences, [])\n",
    "\n",
    "    tokenized_examples = tokenizer(first_sentences,second_sentences,truncation=True)\n",
    "    # 把每个分词器的输出重新分组，每4条数据对应一个题目的4个选项\n",
    "    # 保证模型输入是(batch_size,num_choice,seq_len)的形式\n",
    "    return {k: [v[i:i+4] for i in range(0, len(v), 4)] for k,v in tokenized_examples.items()}"
   ],
   "id": "a52f38dc677c0232"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 代码详解",
   "id": "e991fee12b3064cf"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "# first_sentences = [[context] * 4 for context in examples[\"sent1\"]]",
   "id": "c81e2799a719245c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "假设examples的数据是 examples[\"sent1\"] = [\"A man is cooking\", \"She is running\"]\n",
    "\n",
    "那么就会输出：\n",
    "\n",
    "> first_sentences = [\n",
    ">\n",
    ">   [\"A man is cooking\", \"A man is cooking\", \"A man is cooking\", \"A man is cooking\"],\n",
    ">\n",
    ">   [\"She is running\", \"She is running\", \"She is running\", \"She is running\"]\n",
    ">\n",
    "> ]"
   ],
   "id": "5eb6ed7072e9958b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "# question_headers = examples[\"sent2\"]",
   "id": "941c59a3d3f2b823"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "假设你的数据集有两个样本，因为每个样本都只会有一个sent2，所以这里的question_headers就是：\n",
    "\n",
    "question_headers = [\"He then\", \"She then\"]\n",
    "\n",
    "他会自动把数据集里的样本按属性进行压缩，压缩成一个list"
   ],
   "id": "e5adeb8c2a08d6c1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "# second_sentences = [[f\"{header} {examples[end][i]}\" for end in ending_names] for i, header in enumerate(question_headers)]",
   "id": "6be6c459a625d59e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "假设你的datasets的训练集有两个样本，每个样本对应4个选项，那他的数据结构就是这样的:\n",
    "\n",
    "> examples[\"ending0\"] = [\"eats a sandwich\", \"jumps over a hurdle\"]\n",
    ">\n",
    "> examples[\"ending1\"] = [\"cooks pasta\", \"falls down\"]\n",
    ">\n",
    "> examples[\"ending2\"] = [\"drives a car\", \"wins a race\"]\n",
    ">\n",
    "> examples[\"ending3\"] = [\"washes dishes\", \"sits down\"]\n",
    ">\n",
    "\n",
    "然后把`examples[\"sent2\"][i],examples[\"ending0\"][i],examples[\"ending1\"][i],examples[\"ending2\"][i],examples[\"ending3\"][i]`拼接起来：成为second_sentences：\n",
    "\n",
    "> second_sentences = [\n",
    ">\n",
    ">     [\"He then eats a sandwich\", \"He then cooks pasta\", \"He then drives a car\", \"He then washes dishes\"],\n",
    ">\n",
    ">     [\"She then jumps over a hurdle\", \"She then falls down\", \"She then wins a race\", \"She then sits down\"]\n",
    ">\n",
    "> ]"
   ],
   "id": "7047c1adbd6541e4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 因为现在处理后的first_sent和second_sent都是二维的，tokenizer需要一维的数据，所以把他展开\n",
    "# first_sentences = sum(first_sentences, [])\n",
    "# second_sentences = sum(second_sentences, [])"
   ],
   "id": "c597743d3af7b6c2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "变成这样：\n",
    "\n",
    "> first_sentences = [\n",
    ">\n",
    "> \"A man is cooking\", \"A man is cooking\", \"A man is cooking\", \"A man is cooking\",\n",
    ">\n",
    "> \"She is running\", \"She is running\", \"She is running\", \"She is running\"\n",
    ">\n",
    "> ]\n",
    ">\n",
    "> second_sentences = [\n",
    ">\n",
    "> \"He then eats a sandwich\", \"He then cooks pasta\", \"He then drives a car\", \"He then washes dishes\",\n",
    ">\n",
    "> \"She then jumps over a hurdle\", \"She then falls down\", \"She then wins a race\", \"She then sits down\"\n",
    ">\n",
    "> ]"
   ],
   "id": "54ae399c5dc994e5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# tokenized_examples.items()会返回一个kv对的迭代对象，类似于java的Map.entry\n",
    "\n",
    "# return {k: [v[i:i+4] for i in range(0, len(v), 4)] for k,v in tokenized_examples.items()}"
   ],
   "id": "f9aa0d3258e0858"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "2个样本，每个样本有4个选项，所以tokenizer会输出8个特征集；\n",
    "\n",
    "input_ids = [[101, 123, 102], [101, 456, 102], ..., 共8条]\n",
    "\n",
    "返回时会分为：把8个特征集按4个元素平均分为各个样本；\n",
    "\n",
    "> input_ids = [\n",
    ">\n",
    ">     [[101, 123, 102], [101, 456, 102], [101, 789, 102], [101, 321, 102]],  # 第1题4个选项\n",
    ">\n",
    ">     [[101, 654, 102], [101, 987, 102], [101, 741, 102], [101, 852, 102]]   # 第2题4个选项\n",
    ">\n",
    "> ]"
   ],
   "id": "198ccd883f0a5956"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "我们把预处理后的样本特征进行解码，进一步理解：",
   "id": "6f770ed7bf6f921"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# features = preprocess_function(examples)\n",
    "# print([tokenizer.decode(features[\"input_ids\"][3][i]) for i in range(4)])"
   ],
   "id": "31dd472f95f37fe8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "可以看到，解码后的数据样本就是【题目+选项的序列对】，4个序列对组成一个样本；\n",
    "\n",
    "> [\n",
    ">\n",
    ">     \"[CLS] a drum line passes by walking down the street playing their instruments. [SEP] members of the procession are playing ping pong and celebrating one left each in quick. [SEP]\",\n",
    ">\n",
    ">     \"[CLS] a drum line passes by walking down the street playing their instruments. [SEP] members of the procession wait slowly towards the cadets. [SEP]\",\n",
    ">\n",
    ">     \"[CLS] a drum line passes by walking down the street playing their instruments. [SEP] members of the procession makes a square call and ends by jumping down into snowy streets where fans begin to take their positions. [SEP]\",\n",
    ">\n",
    ">     \"[CLS] a drum line passes by walking down the street playing their instruments. [SEP] members of the procession play and go back and forth hitting the drums while the audience claps for them. [SEP]\"\n",
    "> ]\n",
    ">"
   ],
   "id": "faca2df85394d275"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "同样的，我们需要将预处理后的字典数据映射会datasets供模型训练时提取；",
   "id": "1bfa84be0750c947"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "encoded_datasets = datasets.map(preprocess_function, batched=True)",
   "id": "1c39e0651aa3b360"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "现在需要自定义DataLoader，让模型知道怎么从预处理的数据集中获取数据进行训练；",
   "id": "7015a2a08aa4bf45"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from dataclasses import dataclass\n",
    "from transformers.tokenization_utils_base import PreTrainedTokenizerBase, PaddingStrategy\n",
    "from typing import Optional, Union\n",
    "import torch\n",
    "\n",
    "@dataclass\n",
    "class DataCollatorForMultipleChoice:\n",
    "    \"\"\"\n",
    "    用于批处理多选数据时动态填充序列的数据收集器；\n",
    "    padding默认为True，每个序列都会填充到当前批次中，选项的最大长度\n",
    "    \"\"\"\n",
    "    tokenizer: PreTrainedTokenizerBase # 传入的分词器，用于动态填充序列\n",
    "    padding: Union[bool, str, PaddingStrategy] = True # 是否填充（True 自动按最长序列，或指定 \"max_length\"）\n",
    "    max_length: Optional[int] = None # 填充/截断到的最大长度\n",
    "    pad_to_multiple_of: Optional[int] = None # 可选，将序列填充到某个倍数长度（比如 GPU Tensor Core 需要 8 的倍数）\n",
    "\n",
    "    def __call__(self, features):\n",
    "        label_name = \"label\" if \"label\" in features[0].keys() else \"labels\"\n",
    "        # 提取所有样本的标签，并从 features 中删除标签字段（避免干扰后续 padding）\n",
    "        labels = [feature.pop(label_name) for feature in features]\n",
    "        batch_size = len(features)\n",
    "        # 每个样本的选项数\n",
    "        num_choices = len(features[0][\"input_ids\"])\n",
    "        # 每条数据按照选项数展开\n",
    "        flattened_features = [[{k: v[i] for k, v in feature.items()} for i in range(num_choices)] for feature in features]\n",
    "        # 展开成一维\n",
    "        flattened_features = sum(flattened_features, [])\n",
    "        # 对所有展开后的序列进行动态填充，返回 PyTorch tensor 格式\n",
    "        batch = self.tokenizer.pad(\n",
    "            flattened_features,\n",
    "            padding=self.padding,\n",
    "            max_length=self.max_length,\n",
    "            pad_to_multiple_of=self.pad_to_multiple_of,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        # 将填充好的 tensor 重新 reshape 回 (batch_size, num_choices, seq_len)，还原多选的结构\n",
    "        batch = {k: v.view(batch_size, num_choices, -1) for k, v in batch.items()}\n",
    "        # 将提取的标签加回去，作为最终返回的 batch\n",
    "        batch[\"labels\"] = torch.tensor(labels, dtype=torch.int64)\n",
    "        return batch"
   ],
   "id": "fcc303bd40d13f8c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "测试这个函数能不能用，因为这些升维，和降维操作，都是容易出错的；",
   "id": "9fc18a1a932962a9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "accepted_keys = [\"input_ids\", \"attention_mask\", \"label\"]\n",
    "features = [{k: v for k, v in encoded_datasets[\"train\"][i].items() if k in accepted_keys} for i in range(10)]\n",
    "batch = DataCollatorForMultipleChoice(tokenizer)(features)\n",
    "print(batch[\"input_ids\"].shape)\n",
    "print(\"=============\")\n",
    "print([tokenizer.decode(batch[\"input_ids\"][8][i].tolist()) for i in range(4)])\n",
    "print(\"=============\")\n",
    "show_one(datasets[\"train\"][8])"
   ],
   "id": "ceaa9f1e68d26464"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 封装评估函数",
   "id": "fbcdbc22548160ef"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "\n",
    "def compute_metrics(eval_predictions):\n",
    "    predictions, label_ids = eval_predictions\n",
    "    preds = np.argmax(predictions, axis=1)\n",
    "    return {\"accuracy\": (preds == label_ids).astype(np.float32).mean().item()}"
   ],
   "id": "41c6bf63594ca3ed"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 构建训练参数配置器",
   "id": "1a617701e79e1c26"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from transformers import AutoModelForMultipleChoice, TrainingArguments\n",
    "\n",
    "model = AutoModelForMultipleChoice.from_pretrained(model_checkpoint)\n",
    "\n",
    "args = TrainingArguments(\n",
    "    \"test-swag\",\n",
    "    eval_strategy = \"epoch\",\n",
    "    learning_rate=5e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    report_to=\"none\"\n",
    ")"
   ],
   "id": "d5cfb97c09e9c737"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 构建训练器",
   "id": "4fb8f3bfeaf89180"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=encoded_datasets[\"train\"],\n",
    "    eval_dataset=encoded_datasets[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=DataCollatorForMultipleChoice(tokenizer),\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ],
   "id": "aea9a5df082b4ebe"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 开始训练",
   "id": "2c9537e3deeb39b6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "trainer.train()",
   "id": "58c0c7f272eaf07d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 模型评估",
   "id": "165e534ed9cb34e6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "trainer.evaluate()",
   "id": "9bfccb93ea4037b2"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
